---
layout: archive
author_profile: true
---
<h2>Research</h2>

<body>
  <p>Artificial life is often thought of as complicated, expensive, large-scale
  implementations of humanoid robots, but the first life-like robotic behaviors
  may be the result of simple interactions collectively producing emergent behaviors.

  <br><br>Both the design of sensing, computation, and actuation components of
  <i>individual</i> robots, and predicting and understanding the
  <i>collective</i> interactions of groups of agents composed of these elements,
  are key to developing properties like self-organization and emergent computation.</p>

  <h3>Algorithmic Robot Design</h3>
  <p>Robots traditionally require three elements: sensors, computation, and actuators.
  How should these components be assembled into a robot designed for a specific task?

  <br><br><b>Design Sensitivities.</b>
  Robot performance is clearly sensitive to changes in design, and determining how much
  a robot might benefit from the addition of different components or other morphologial changes
  could greatly impact a robot's capabilities.

  <br><br>For example, how does one determine the sensitivity of the design of a robotic leg (intended
  for walking) to the introduction of a knee? How does it affect the robot if the
  knee is a simple revolute joint, or if it has a motor? I am currently investigating this problem,
  both through the lens of reinforcement learning and using methods from switched systems theory.

  <br><br><b>Combinatoric Components.</b>
  Another important element of robot design is the combinatorics of components. Sensors
  and actuators are by no means independent components on a
  robot. For example, a camera (which is a sensor) is useless at night without
  a flashlight (an actuator, of sorts). Likewise, a flashlight is of no benefit to a
  robot that doesnâ€™t have a camera.

  <br><br>For control, exploitable sensor-actuator pairs are valuable. In my
  <a href="../publications">Master's Thesis</a>,  as well as a
  <a href="../publications">book chapter</a>, I introduced a novel method for
  designing a simple robot when given a finite library of sensors and actuators.


  <br><br><b>Information Flow.</b>
  A central idea in robotics and control is information flow from the environment to
  the robot. What is the relationship between the body of a robot and its desired task,
  without control? If the relative entropy between the initial conditions of the
  robot and its goal task is small (meaning that the goal task is not
  far from the initial conditions of the robot), then not much control information
  is necessary to achieve the task. In other words, if a task is well embodied by a robot, only a simple
  control policy is necessary to execute it. Otherwise more information, in the
  form of a complex control policy, is necessary.

  <br><br><i>Task embodiment</i> is a measure of how much information a body encodes
  about a task. Improving a physical robot design (relative to a certain task) can be thought of as moving
  task information from centralized computations in control calculations
  to embedded computation in the physical body. This principle of information
  flow, and trade-offs of having control information be in the physical design of
  the body or in the computerized controller of a robot, are one way to formally
  think about robot designs. I introduced the concept of task embodiment in two publictions:
  a <a href="../publications">WAFR paper</a> and a <a href="../publications">RA-L paper</a>.
  </p>

  <h3>Collective Behaviors and Emergent Computation</h3>
  <p>The main element of emergent behavior is the ability of the local
  sensing and actuation of individuals to result in significant, global
  capabilities of the collective. How can a methodology be formed with
  which goals for the ensemble can be transformed into physical designs of individual
  robots?

  <br><br><b>Stochastic Robotics.</b>
  First, emergent behaviors must be able to be identified and exploited.
  In a recent <a href="../publications">Science Robotics paper</a>, my colleagues and I demonstrated
  that directed locomotion could be achieved as a result of stochastic interactions,
  by recognizing and utilizing emergent behaviors.  I implemented a nonparametric algorithm to take
  advantage of broken symmetries in the system and execute sophisticated collective
  behaviors, all with minimal, local sensing and actuation capabilities.

  <br><br><b>Reinforcement Learning in Particle Robots.</b>
  Through collaboration with chemical engineers at MIT, including
  <a href="https://albert-t-liu.com/">Albert T. Liu</a>, I have been
  considering the problem of designing microscopic robots
  to achieve complex goals in a stochastic environment (for example, navigating
  the circulatory system to assisst in an immune response), where they might have
  to change their control policies, communicate with each other, and deal with uncertainty
   -- all with minimal capabilities and only a few bits of memory. This project is
   in progress, and it is an exciting application of my work in algorithmic robot
   design and collective and emergent behaviors.
</body>
